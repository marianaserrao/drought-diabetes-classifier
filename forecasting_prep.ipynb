{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas                  as pd\n",
    "import matplotlib.pyplot       as plt\n",
    "import seaborn                 as sns\n",
    "import numpy                   as np\n",
    "from itertools                 import count\n",
    "from sklearn.metrics.pairwise  import euclidean_distances\n",
    "from sklearn.neighbors         import KNeighborsClassifier\n",
    "from sklearn.metrics           import accuracy_score, confusion_matrix\n",
    "from sklearn.naive_bayes       import GaussianNB\n",
    "from sklearn.preprocessing     import StandardScaler, Normalizer\n",
    "from sklearn.feature_selection import SequentialFeatureSelector\n",
    "from sklearn.metrics           import mean_squared_error\n",
    "from scipy.signal              import savgol_filter\n",
    "from statsmodels.tsa.holtwinters import SimpleExpSmoothing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Understanding the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Read the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('data/drought_forecasting.csv', dayfirst=True, parse_dates =[\"date\"], index_col =\"date\")\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nullValues = data.isnull().sum()\n",
    "nullValues"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Data types and data summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.describe()\n",
    "# looking the data description is already possible to see that aggregate the data could be not so good, \n",
    "# because there is a high value in PRECTOT that can be an outliers and will 'desapear' in the aggregation process.\n",
    "# So use the atomic granularity possibly is the best option"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"data['day'] = pd.DatetimeIndex(data['date'], dayfirst=True).day\n",
    "data['month'] = pd.DatetimeIndex(data['date'], dayfirst=True).month\n",
    "data['year'] = pd.DatetimeIndex(data['date'], dayfirst=True).year\n",
    "data = data[[col for col in data if col not in ['QV2M']] + ['QV2M']]\n",
    "data.pop('date')\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Data Profiling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 1.1. Data Granularity "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### 1.1.1. Resample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Granularity: atomic (daily)\n",
    "daily_data = data\n",
    "# Granularity: weekly\n",
    "weekly_data = data.resample('W').mean()\n",
    "# Granularity: monthly\n",
    "monthly_data = data.resample('M').mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 1.2. Data Distribution and Stationarity  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### 1.2.1. Boxplots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def boxplot(data, filename):\n",
    "    \"\"\"\"\"\"\n",
    "\n",
    "    #fig, ax = plt.subplots()\n",
    "    sns.boxplot(data=data)\n",
    "    plt.savefig('plots/'+filename + \".png\")\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "boxplot(daily_data, 'boxplot_drought_forecasting_dailySeparated')\n",
    "boxplot(weekly_data, 'boxplot_drought_forecasting_weeklySeparated')\n",
    "boxplot(monthly_data, 'boxplot_drought_forecasting_monthlySeparated')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### 1.2.2. Histograms "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def histograms(data, filename, dimension):\n",
    "    i, j = dimension\n",
    "    fig, ax = plt.subplots(i, j, figsize=(24, 14))\n",
    "    \n",
    "    for position in range(len(data.columns)):\n",
    "        col = data.columns[position]\n",
    "\n",
    "        pos_i = position//j\n",
    "        pos_j = position%j\n",
    "\n",
    "        ax[pos_i][pos_j].hist(data[col])\n",
    "        ax[pos_i][pos_j].set_title(col)\n",
    "        ax[pos_i][pos_j].legend()\n",
    "        \n",
    "    plt.savefig('plots/' + filename + '.png')\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "histograms(daily_data, 'hist_drought_forecasting_dailySeparated', (2, 4))\n",
    "histograms(weekly_data, 'hist_drought_forecasting_weeklySeparated', (2, 4))\n",
    "histograms(monthly_data, 'hist_drought_forecasting_monthlySeparated', (2, 4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### 1.2.3. Stationarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_stationarity(data, filename, dimension):\n",
    "    i, j = dimension\n",
    "    fig, ax = plt.subplots(i, j, figsize=(24, 14))\n",
    "    \n",
    "    for position in range(len(data.columns)):\n",
    "        col = data.columns[position]\n",
    "\n",
    "        pos_i = position//j\n",
    "        pos_j = position%j\n",
    "\n",
    "        ax[pos_i][pos_j].plot(data[col])\n",
    "        ax[pos_i][pos_j].set_title(col)\n",
    "        ax[pos_i][pos_j].legend()\n",
    "        \n",
    "    plt.savefig('plots/' + filename + '.png')\n",
    "    plt.close()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_stationarity(daily_data, 'stationarity_drought_forecantig_dailySeparated', (2, 4))\n",
    "plot_stationarity(weekly_data, 'stationarity_drought_forecantig_weeklySeparated', (2, 4))\n",
    "plot_stationarity(monthly_data, 'stationarity_drought_forecantig_monthlySeparated', (2, 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def temporal_data_split_forPersistence(data, train_size=0.80):\n",
    "\n",
    "    data = pd.DataFrame(data)\n",
    "    lim = round(len(data)*train_size)\n",
    "\n",
    "    tmp_data_x = data.shift(1)\n",
    "    X_train = tmp_data_x.iloc[1:lim]\n",
    "    X_test = tmp_data_x.iloc[lim:]\n",
    "    Y_train = data.iloc[1:lim]\n",
    "    Y_test = data.iloc[lim:]\n",
    "    return X_train, X_test, Y_train, Y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# persistence model\n",
    "def model_persistence(x):\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def persistence_model(X_test, Y_test):\n",
    "\n",
    "   predictions = []\n",
    "   for x in np.array(X_test):\n",
    "      yhat = model_persistence(x)\n",
    "      predictions.append(yhat)\n",
    "      \n",
    "   rmse = (mean_squared_error(Y_test, predictions))**(1/2)\n",
    "   res = [Y_test, pd.DataFrame(predictions, index=X_test.index)]\n",
    "   return res, rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_persistence(data, columns,  filename, dimension):\n",
    "    i, j = dimension\n",
    "    fig, ax = plt.subplots(i, j, figsize=(35, 25))\n",
    "    \n",
    "    for position in range(len(columns)):\n",
    "        col = columns[position]\n",
    "\n",
    "        pos_i = position//j\n",
    "        pos_j = position%j\n",
    "\n",
    "        ax[pos_i][pos_j].plot(data[position][0], color = \"red\")\n",
    "        ax[pos_i][pos_j].plot(data[position][1], color = \"green\")\n",
    "        plt.legend(col)\n",
    "        plt.xticks(rotation=45)\n",
    "\n",
    "    plt.savefig('plots/' + filename + '.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_daily_persistenceRes = []\n",
    "data_weekly_persistenceRes = []\n",
    "data_monthly_persistenceRes = []\n",
    "\n",
    "stats_ps = pd.DataFrame(columns=['var', 'rmse - daily', 'rmse - weekly', 'rmse - monthly'])\n",
    "\n",
    "c = 0\n",
    "for col in daily_data.columns:\n",
    "\n",
    "    X_train_d, X_test_d, Y_train_d, Y_test_d = temporal_data_split_forPersistence(daily_data[col])\n",
    "    X_train_w, X_test_w, Y_train_w, Y_test_w = temporal_data_split_forPersistence(weekly_data[col])\n",
    "    X_train_m, X_test_m, Y_train_m, Y_test_m = temporal_data_split_forPersistence(monthly_data[col])\n",
    "\n",
    "    res_ps_daily, rmse_ps_daily = persistence_model(X_test_d, Y_test_d)\n",
    "    res_ps_weekly, rmse_ps_weekly = persistence_model(X_test_w, Y_test_w)\n",
    "    res_ps_monthly, rmse_ps_monthly = persistence_model(X_test_m, Y_test_m)\n",
    "\n",
    "    data_daily_persistenceRes.append(res_ps_daily)\n",
    "    data_weekly_persistenceRes.append(res_ps_weekly)\n",
    "    data_monthly_persistenceRes.append(res_ps_monthly)\n",
    "\n",
    "    stats_ps[c] = [col, rmse_ps_daily, rmse_ps_weekly, rmse_ps_monthly]\n",
    "    \n",
    "    c+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_persistence(data_daily_persistenceRes, daily_data.columns, 'drought_forecasting_persistence_daily', (2, 4))\n",
    "plot_persistence(data_weekly_persistenceRes, daily_data.columns, 'drought_forecasting_persistence_weekly', (2, 4))\n",
    "plot_persistence(data_monthly_persistenceRes, daily_data.columns, 'drought_forecasting_persistence_monthly', (2, 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# smoothing\n",
    "def smooth_sg1(data, frac, p, filename, dimension):\n",
    "\n",
    "    i, j = dimension\n",
    "    fig, ax = plt.subplots(i, j, figsize=(35, 25))\n",
    "    data_filtered = []\n",
    "    for pos in range(len(data.columns)):\n",
    "        x = data[data.columns[pos]]\n",
    "        w = int(len(x)*frac)\n",
    "        x_filtered = savgol_filter(x, w, p)\n",
    "        data_filtered.append(x_filtered)\n",
    "\n",
    "        pos_i = pos//j\n",
    "        pos_j = pos%j\n",
    "\n",
    "        ax[pos_i][pos_j].plot(x)\n",
    "        ax[pos_i][pos_j].plot(x_filtered, color = \"green\")\n",
    "        plt.legend(x)\n",
    "        #plt.xticks(rotation=45)\n",
    "\n",
    "    \n",
    "    plt.savefig('plots/' + filename + '.png')\n",
    "    return data_filtered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ses(data, s_level, filename, dimension):\n",
    "\n",
    "    i, j = dimension\n",
    "    fig, ax = plt.subplots(i, j, figsize=(35, 25))\n",
    "    data_filtered = []\n",
    "    \n",
    "\n",
    "    for pos in range(len(data.columns)):\n",
    "\n",
    "        x = data[data.columns[pos]]\n",
    "        model = SimpleExpSmoothing(x)\n",
    "        x_filtered = model.fit(smoothing_level=s_level, optimized=False)\n",
    "        print(x_filtered)\n",
    "        data_filtered.append(x_filtered.fittedvalues)\n",
    "\n",
    "        pos_i = pos//j\n",
    "        pos_j = pos%j\n",
    "\n",
    "        ax[pos_i][pos_j].plot(x)\n",
    "        ax[pos_i][pos_j].plot(x_filtered.fittedvalues, color = \"green\")\n",
    "        plt.legend(x)\n",
    "        #plt.xticks(rotation=45)\n",
    "\n",
    "    \n",
    "    plt.savefig('plots/' + filename + '.png')\n",
    "    return data_filtered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_smooth_frac001 = smooth_sg1(daily_data, 0.01, 3, 'drought_forecasting_smoothing_frac001_p3',(2, 4))\n",
    "data_smooth_frac005 = smooth_sg1(daily_data, 0.05, 3, 'drought_forecasting_smoothing_frac005_p3',(2, 4))\n",
    "data_smooth_frac01 = smooth_sg1(daily_data, 0.1, 3, 'drought_forecasting_smoothing_frac01_p3',(2, 4))\n",
    "\n",
    "data_smooth_ses_01 = ses(daily_data, 0.1, 'drought_forecasting_smoothing_ses_01', (2,4))\n",
    "data_smooth_ses_02 = ses(daily_data, 0.2, 'drought_forecasting_smoothing_ses_02', (2,4))\n",
    "data_smooth_ses_05 = ses(daily_data, 0.5, 'drought_forecasting_smoothing_ses_05', (2,4))\n",
    "\n",
    "pers_res = pd.DataFrame(columns=['col', 'rmse_sg_0', 'rmse_sg_1', 'rmse_sg_2', 'rmse_ses_0', 'rmse_ses_1', 'rmse_ses_2'])\n",
    "\n",
    "for col in range(len(daily_data.columns)):\n",
    "\n",
    "    X_train_0, X_test_0, Y_train_0, Y_test_0 = temporal_data_split_forPersistence(data_smooth_frac001[col])\n",
    "    X_train_1, X_test_1, Y_train_1, Y_test_1 = temporal_data_split_forPersistence(data_smooth_frac005[col])\n",
    "    X_train_2, X_test_2, Y_train_2, Y_test_2 = temporal_data_split_forPersistence(data_smooth_frac01[col])\n",
    "\n",
    "    X_train_3, X_test_3, Y_train_3, Y_test_3 = temporal_data_split_forPersistence(data_smooth_ses_01[col])\n",
    "    X_train_4, X_test_4, Y_train_4, Y_test_4 = temporal_data_split_forPersistence(data_smooth_ses_02[col])\n",
    "    X_train_5, X_test_5, Y_train_5, Y_test_5 = temporal_data_split_forPersistence(data_smooth_ses_05[col])\n",
    "\n",
    "\n",
    "    res_ps_0, rmse_ps_0 = persistence_model(X_test_0, Y_test_0)\n",
    "    res_ps_1, rmse_ps_1 = persistence_model(X_test_1, Y_test_1)\n",
    "    res_ps_2, rmse_ps_2 = persistence_model(X_test_2, Y_test_2)\n",
    "\n",
    "    res_ps_3, rmse_ps_3 = persistence_model(X_test_3, Y_test_3)\n",
    "    res_ps_4, rmse_ps_4 = persistence_model(X_test_4, Y_test_4)\n",
    "    res_ps_5, rmse_ps_5 = persistence_model(X_test_5, Y_test_5)\n",
    "\n",
    "\n",
    "    pers_res.loc[col] = [col, rmse_ps_0, rmse_ps_1, rmse_ps_2, rmse_ps_3, rmse_ps_4, rmse_ps_5]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pers_res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "daily_data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# choice: simple exponential smoothing with level = 0.1\n",
    "data_pos_smoothing = pd.DataFrame(data_smooth_ses_01)\n",
    "data_pos_smoothing = data_pos_smoothing.transpose()\n",
    "data_pos_smoothing = data_pos_smoothing.rename(columns = {0:\"PRECTOT\", 1:\"PS\", 1:\"T2M\", 3:\"T2MDEW\", 4:\"T2MWET\", 5:\"TS\", 6:\"QV2M\"})\n",
    "data_pos_smoothing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# differenciation\n",
    "\n",
    "# one differenciation\n",
    "data_one_diff = data_pos_smoothing.diff(axis = 0, periods = 1)\n",
    "# two differenciation\n",
    "data_two_diff = data_pos_smoothing.diff(axis = 0, periods = 1)\n",
    "data_two_diff = data_two_diff.diff(axis = 0, periods = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_one_diff = data_one_diff.iloc[1:,:]\n",
    "data_two_diff = data_two_diff.iloc[2:,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res_diff = pd.DataFrame(columns=['col', 'rmse_oneDiff', 'rmse_twoDiff', 'rmse_noDiff'])\n",
    "\n",
    "for col in range(len(data_one_diff.columns)):\n",
    "\n",
    "    X_train_oneDiff, X_test_oneDiff, Y_train_oneDiff, Y_test_oneDiff = temporal_data_split_forPersistence(data_one_diff.iloc[:,col])\n",
    "    X_train_twoDiff, X_test_twoDiff, Y_train_twoDiff, Y_test_twoDiff = temporal_data_split_forPersistence(data_two_diff.iloc[:,col])\n",
    "    X_train_noDiff, X_test_noDiff, Y_train_noDiff, Y_test_noDiff = temporal_data_split_forPersistence(data_pos_smoothing.iloc[:,col])\n",
    "\n",
    "    res_oneDiff, rmse_oneDiff = persistence_model(X_test_oneDiff, Y_test_oneDiff)\n",
    "    res_twoDiff, rmse_twoDiff = persistence_model(X_test_twoDiff, Y_test_twoDiff)\n",
    "    res_noDiff, rmse_noDiff = persistence_model(X_test_noDiff, Y_test_noDiff)\n",
    "    \n",
    "    res_diff.loc[col] = [col, rmse_oneDiff, rmse_twoDiff, rmse_noDiff]\n",
    "\n",
    "X_train_noDiff, X_test_noDiff, Y_train_noDiff, Y_test_noDiff = temporal_data_split_forPersistence(data_one_diff.iloc[:,col])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res_diff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# choice: don't use differenciation\n",
    "data_pos_smoothing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_pos_smoothing.to_csv(\"intermediate_data/data_drought_forecasting_prepared.csv\", encoding='utf-8', columns=data_pos_smoothing.columns, index=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7 (main, Sep  5 2022, 13:12:31) [GCC 11.2.0]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "7d6993cb2f9ce9a59d5d7380609d9cb5192a9dedd2735a011418ad9e827eb538"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
