{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PeG8VqthiYHB"
      },
      "outputs": [],
      "source": [
        "from itertools import count\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn           as sns\n",
        "import numpy             as np\n",
        "from sklearn.metrics.pairwise import euclidean_distances\n",
        "from sklearn.neighbors        import KNeighborsClassifier\n",
        "from sklearn.metrics          import accuracy_score, confusion_matrix\n",
        "from sklearn.naive_bayes      import GaussianNB\n",
        "from sklearn.preprocessing    import StandardScaler, Normalizer\n",
        "from sklearn.feature_selection import SequentialFeatureSelector"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 1. Data Profiling"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "data = pd.read_csv('data/drought_forecasting.csv')\n",
        "data = data.rename(columns = {\"class\" : \"drought\"})\n",
        "data['day'] = pd.DatetimeIndex(data['date'], dayfirst=True).day\n",
        "data['month'] = pd.DatetimeIndex(data['date'], dayfirst=True).month\n",
        "data['year'] = pd.DatetimeIndex(data['date'], dayfirst=True).year\n",
        "data = data[[col for col in data if col not in ['drought']] + ['drought']]\n",
        "data.pop('date')\n",
        "data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### 1.1. Data Dimensionality"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### 1.2. Data Distribution"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "##### 1.2.1. Histograms"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def histograms(data, dimension):\n",
        "    i, j = dimension\n",
        "    fig, ax = plt.subplots(i, j, figsize=(50, 80))\n",
        "    \n",
        "    for position in range(len(data.columns)):\n",
        "        col = data.columns[position]\n",
        "\n",
        "        pos_i = position//j\n",
        "        pos_j = position%j\n",
        "        \n",
        "\n",
        "        dist_0 = data[data['drought']==0][col]\n",
        "        dist_1 = data[data['drought']==1][col]\n",
        "\n",
        "        ax[pos_i][pos_j].hist([dist_0, dist_1],\n",
        "                          stacked=False,\n",
        "                          label=['drought = 0', 'drought = 1'],\n",
        "                          color=['#7547B8', '#8AB847'])\n",
        "        ax[pos_i][pos_j].set_title(col)\n",
        "        ax[pos_i][pos_j].legend()\n",
        "\n",
        "    plt.savefig('plots/drought_hist01.png')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "histograms(data, (9, 6))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "##### 1.2.2. Boxplots"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def boxplotAllInd(data, filename, dimension):\n",
        "    i, j = dimension\n",
        "    fig, ax = plt.subplots(i, j, figsize=(50, 80))\n",
        "    \n",
        "    for position in range(len(data.columns)):\n",
        "        col = data.columns[position]\n",
        "\n",
        "        pos_i = position//j\n",
        "        pos_j = position%j\n",
        "\n",
        "        ax[pos_i][pos_j].boxplot(data[col])\n",
        "        ax[pos_i][pos_j].set_title(col)\n",
        "\n",
        "    plt.savefig('plots/' + filename + '.png')\n",
        "    plt.close()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "boxplotAllInd(data, 'boxplot_drought_classification_allInd', (9, 6))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def boxplot(data, filename):\n",
        "    \"\"\"\"\"\"\n",
        "\n",
        "    sns.set(rc={\"figure.figsize\":(16, 14)})\n",
        "    sns.boxplot(data=data)\n",
        "    plt.xticks(rotation='vertical')\n",
        "    plt.savefig('plots/'+filename + \".png\")\n",
        "    plt.close()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "boxplot(data, 'boxplot_drought_classification_all')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Groups of attributes to plot together: \n",
        "# fips and year\n",
        "# Interval of values: [0,1) - slope1, slope2, slope3, slope4, slope5, slope6, slope7, slope8, aspectN, aspectE, aspectS, aspectW, aspectUnknown\n",
        "# Interval of values: [1,10) - WS10M,WS10M_MIN, WS50M_MIN, SQ1, SQ2, SQ3, SQ4, SQ5, SQ6, SQ7, drought\n",
        "# Interval of values: [0,21) - QV2M,WS10M_MAX, WS10M_RANGE, WS50M, WS50M_MAX, month\n",
        "# Interval of values: [-20, 50) - T2M, T2MDEW, T2MWET, T2M_MAX, T2M_MIN, T2M_RANGE, TS \n",
        "# Interval of values: [-100, 0) - lon\n",
        "# Interval of values: [-100, 0) - lat\n",
        "# Interval of values: [0, 800) - elevation\n",
        "# Interval of values: [0, 102) - WAT_LAND, NVG_LAND, URB_LAND, GRS_LAND, FOR_LAND, CULTRF_LAND, CULTIR_LAND, CULT_LAND, day, PRECTOT\n",
        "\n",
        "dataValuesPerIntervals = [data[[\"slope1\", \"slope2\", \"slope3\", \"slope4\", \"slope5\", \"slope6\", \"slope7\", \n",
        "                                \"slope8\", \"aspectN\", \"aspectE\", \"aspectS\", \"aspectW\", \"aspectUnknown\"]], \n",
        "                            data[[\"WS10M\",\"WS10M_MIN\", \"WS50M_MIN\", \"SQ1\", \"SQ2\", \"SQ3\", \"SQ4\", \"SQ5\", \n",
        "                            \"SQ6\", \"SQ7\", \"drought\"]], \n",
        "                            data[[\"QV2M\",\"WS10M_MAX\", \"WS10M_RANGE\", \"WS50M\", \"WS50M_MAX\", \"month\"]], \n",
        "                            data[[\"T2M\", \"T2MDEW\", \"T2MWET\", \"T2M_MAX\", \"T2M_MIN\", \"T2M_RANGE\", \"TS\"]], \n",
        "                            data[\"lon\"], data[\"lat\"], data[\"elevation\"], data[[\"fips\", \"year\"]],\n",
        "                            data[[\"WAT_LAND\", \"NVG_LAND\", \"URB_LAND\", \"GRS_LAND\", \"FOR_LAND\", \"CULTRF_LAND\", \n",
        "                            \"CULTIR_LAND\", \"CULT_LAND\", \"day\", \"PRECTOT\"]]]\n",
        "\n",
        "filenameC = 0\n",
        "for d in dataValuesPerIntervals:\n",
        "    boxplot(d, \"boxplot_drought_classification_\" + filenameC)\n",
        "    filenameC+=1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### 1.3. Data Granularity\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### 1.4. Sparsity"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def heatmap(data):\n",
        "    heatmap = data.corr()\n",
        "    f, ax = plt.subplots(figsize=(15,15))\n",
        "    sns.heatmap(heatmap,\n",
        "                cmap=sns.color_palette(\"RdBu_r\", 1000),\n",
        "                vmin=-1,\n",
        "                vmax=1,\n",
        "                square=True)\n",
        "    \n",
        "    plt.savefig('plots/drought_heatmap01.png')\n",
        "    plt.close()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "heatmap(data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def scatterplots(data):\n",
        "    \"\"\" Given the data, the function plot the scatter plots \"\"\"\n",
        "\n",
        "    figur = sns.pairplot(data, diag_kind='hist')\n",
        "    fig = figur.fig\n",
        "    fig.savefig(\"plots/scatterplotGeneral.png\")\n",
        "    plt.close()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "scatterplots(data)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 2. Data Preparation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### 2.1. Data types and summary"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "data.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "data.describe()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "data.dtypes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "fipsCount = data['fips'].value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "dtypesCount = data.dtypes\n",
        "dfDtypesCount = pd.DataFrame(dtypesCount)\n",
        "sumDtypes = dfDtypesCount.value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "uniqueValues = data['fips'].nunique()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### 2.2. Missing Values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "nullValues = data.isnull().sum()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### 2.3. Models to evaluate the intermediate steps"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GAvEKogprefJ"
      },
      "outputs": [],
      "source": [
        "def knn(X_train, X_test, Y_train, Y_test):\n",
        "\n",
        "    # p=2 resultou numa acurácia menor\n",
        "    model = KNeighborsClassifier(p=1)\n",
        "    model.fit(X_train, Y_train)\n",
        "    Y_pred = model.predict(X_test)\n",
        "    tn, fp, fn, tp = confusion_matrix(Y_test, Y_pred).ravel()\n",
        "    return accuracy_score(Y_test, Y_pred), tn, fp, fn, tp\n",
        "\n",
        "# Naive Bayes\n",
        "def nb(X_train, X_test, Y_train, Y_test):\n",
        "\n",
        "    model = GaussianNB()\n",
        "    model.fit(X_train, Y_train)\n",
        "    Y_pred = model.predict(X_test)\n",
        "    tn, fp, fn, tp = confusion_matrix(Y_test, Y_pred).ravel()\n",
        "    return accuracy_score(Y_test, Y_pred), tn, fp, fn, tp\n",
        "\n",
        "\n",
        "def temporal_data_split(data, target, train_size=0.95):\n",
        "\n",
        "    lim = round(len(data)*train_size)\n",
        "    tmp_data_train = data.loc[0:lim]\n",
        "    tmp_data_test = data.loc[lim:]\n",
        "    X_train = tmp_data_train.drop(target,axis=1) \n",
        "    Y_train = tmp_data_train[target] \n",
        "    X_test = tmp_data_test.drop(target,axis=1)\n",
        "    Y_test = tmp_data_test[target]\n",
        "    return X_train, X_test, Y_train, Y_test"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### 2.4. Outliers Treatment"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "w0Dr7oj3rips"
      },
      "outputs": [],
      "source": [
        "# test_outliers() is a method that test a set of parameters using the distance metodology\n",
        "# parameters \n",
        "# - r: is the ratio that defines the neighborhood\n",
        "# - f: is the data fraction that should be in the neighborhood, \n",
        "# - params: list of tuples where the first element is r and the second is f. it's used to select the outliers, and subsequently \n",
        "# train and test the data\n",
        "#  \n",
        "params = [(298, 0.01), (298, 0.05), (298, 0.1), (298, 0.2), (298, 0.5), \n",
        "          (574, 0.01), (574, 0.05), (574, 0.1), (574, 0.2), (574, 0.5),\n",
        "          (1000, 0.01), (1000, 0.05), (1000, 0.1), (1000, 0.2), (1000, 0.5)]\n",
        "\n",
        "def test_outliers(data, params):\n",
        "    \"\"\"\"\"\"\n",
        "\n",
        "    test_outliers_stats = pd.DataFrame(columns=['r', 'f', 'n_outliers', \n",
        "                                                'knn_accuracy', 'knn_tn', 'knn_fp', 'knn_fn', 'knn_tp', \n",
        "                                                'nb_accuracy', 'nb_tn', 'nb_fp', 'nb_fn', 'nb_tp'])\n",
        "    \n",
        "    outliers = [[[], 0], [[], 0], [[], 0], [[], 0], [[], 0],\n",
        "                [[], 0], [[], 0], [[], 0], [[], 0], [[], 0],\n",
        "                [[], 0], [[], 0], [[], 0], [[], 0], [[], 0]]\n",
        "\n",
        "    lenD = len(data)\n",
        "    for c in range(len(data)):\n",
        "        euclidean_matrix = euclidean_distances(data.iloc[[c]], data)\n",
        "        \n",
        "        for p in range(len(params)):\n",
        "            tmp_df = pd.DataFrame(euclidean_matrix)\n",
        "            tmp_df = tmp_df < params[p][0]\n",
        "            frac = params[p][1] * lenD\n",
        "            if tmp_df.values.sum() < frac:\n",
        "                outliers[p][0].append(c)\n",
        "                outliers[p][1]+=1\n",
        "\n",
        "    c = 0\n",
        "    for c in range(len(outliers)):\n",
        "\n",
        "        dataOutliers = data.drop(outliers[c][0], axis=0)\n",
        "\n",
        "        X_train, X_test, Y_train, Y_test = temporal_data_split(dataOutliers, 'drought')\n",
        "        if len(X_train) != 0 and len(X_test) != 0 and  len(Y_train) != 0 and  len(Y_test) != 0:\n",
        "            knn_acc, knn_tn, knn_fp, knn_fn, knn_tp = knn(X_train, X_test, Y_train, Y_test)\n",
        "            nb_acc, nb_tn, nb_fp, nb_fn, nb_tp  = nb(X_train, X_test, Y_train, Y_test)\n",
        "            test_outliers_stats.loc[c] = [params[c][0], params[c][1], outliers[c][1], knn_acc, knn_tn, knn_fp, knn_fn, knn_tp, nb_acc, nb_tn, nb_fp, nb_fn, nb_tp]\n",
        "\n",
        "    X_train, X_test, Y_train, Y_test = temporal_data_split(data, 'drought')\n",
        "    knn_acc, knn_tn, knn_fp, knn_fn, knn_tp = knn(X_train, X_test, Y_train, Y_test)\n",
        "    nb_acc, nb_tn, nb_fp, nb_fn, nb_tp  = nb(X_train, X_test, Y_train, Y_test)\n",
        "    test_outliers_stats.loc[c+1] = [0, 0, 0, \n",
        "                                                    knn_acc, knn_tn, knn_fp, knn_fn, knn_tp,\n",
        "                                                    nb_acc, nb_tn, nb_fp, nb_fn, nb_tp]\n",
        "\n",
        "    return test_outliers_stats"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3Mf0y3pvxolX"
      },
      "outputs": [],
      "source": [
        "countOutliers = 0\n",
        "pos_outliers = []\n",
        "frac = 0.05*len(data)\n",
        "for c in range(len(data)):\n",
        "    euclidean_matrix = euclidean_distances(data.iloc[[c]], data)\n",
        "    tmp_df = pd.DataFrame(euclidean_matrix)\n",
        "    tmp_df = tmp_df < 299\n",
        "    if tmp_df.values.sum() < frac:\n",
        "        countOutliers+=1\n",
        "        pos_outliers.append(c)\n",
        "\n",
        "dataWithoutOutliers = data.drop(pos_outliers, axis=0)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### 2.5. Scaling"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "dXAZ7MA85DL_",
        "outputId": "3539a31e-67a0-41cc-e302-33afe78c4bd9"
      },
      "outputs": [],
      "source": [
        "dataWithoutOutliers.index = range(0,len(dataWithoutOutliers))\n",
        "dataWithoutOutliers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BQO09jdXzJRb"
      },
      "outputs": [],
      "source": [
        "test_scaling_stats = pd.DataFrame(columns=['method', \n",
        "                                                'knn_accuracy', 'knn_tn', 'knn_fp', 'knn_fn', 'knn_tp', \n",
        "                                                'nb_accuracy', 'nb_tn', 'nb_fp', 'nb_fn', 'nb_tp'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "##### 2.5.1. Standardization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Mq8DkqOu6HT2"
      },
      "outputs": [],
      "source": [
        "std_scaler = StandardScaler()\n",
        "tmp_dataWithoutOutliers = dataWithoutOutliers.drop('drought', axis=1)\n",
        "data_std = std_scaler.fit_transform(tmp_dataWithoutOutliers)\n",
        "data_std = pd.DataFrame(data_std, columns=tmp_dataWithoutOutliers.columns)\n",
        "data_std['drought'] = dataWithoutOutliers['drought']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# stats\n",
        "X_train, X_test, Y_train, Y_test = temporal_data_split(data_std, 'drought')\n",
        "knn_acc, knn_tn, knn_fp, knn_fn, knn_tp = knn(X_train, X_test, Y_train, Y_test)\n",
        "nb_acc, nb_tn, nb_fp, nb_fn, nb_tp  = nb(X_train, X_test, Y_train, Y_test)\n",
        "\n",
        "test_scaling_stats.loc[0] = ['standardization', \n",
        "                            knn_acc, knn_tn, knn_fp, knn_fn, knn_tp,\n",
        "                            nb_acc, nb_tn, nb_fp, nb_fn, nb_tp]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "data_std.to_csv(\"/intermediate_data/data_step_std.csv\", encoding='utf-8', index=False, columns=data_std.columns)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "##### 2.5.2. Normalization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "G9XpvJD5ywPW"
      },
      "outputs": [],
      "source": [
        "\n",
        "norm = Normalizer()\n",
        "tmp_dataWithoutOutliers = dataWithoutOutliers.drop('drought', axis=1)\n",
        "data_norm = norm.fit_transform(tmp_dataWithoutOutliers)\n",
        "data_norm = pd.DataFrame(data_norm, columns=tmp_dataWithoutOutliers.columns)\n",
        "data_norm['drought'] = dataWithoutOutliers['drought']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# stats\n",
        "X_train, X_test, Y_train, Y_test = temporal_data_split(data_norm, 'drought')\n",
        "knn_acc, knn_tn, knn_fp, knn_fn, knn_tp = knn(X_train, X_test, Y_train, Y_test)\n",
        "nb_acc, nb_tn, nb_fp, nb_fn, nb_tp  = nb(X_train, X_test, Y_train, Y_test)\n",
        "\n",
        "test_scaling_stats.loc[1] = ['normalization', \n",
        "                            knn_acc, knn_tn, knn_fp, knn_fn, knn_tp,\n",
        "                            nb_acc, nb_tn, nb_fp, nb_fn, nb_tp]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "##### 2.5.3. No changes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ya_6h3ZczpNC"
      },
      "outputs": [],
      "source": [
        "X_train, X_test, Y_train, Y_test = temporal_data_split(dataWithoutOutliers, 'drought')\n",
        "knn_acc, knn_tn, knn_fp, knn_fn, knn_tp = knn(X_train, X_test, Y_train, Y_test)\n",
        "nb_acc, nb_tn, nb_fp, nb_fn, nb_tp  = nb(X_train, X_test, Y_train, Y_test)\n",
        "\n",
        "test_scaling_stats.loc[2] = ['none', \n",
        "                            knn_acc, knn_tn, knn_fp, knn_fn, knn_tp,\n",
        "                            nb_acc, nb_tn, nb_fp, nb_fn, nb_tp]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "##### 2.5.4. Stats"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 143
        },
        "id": "3UFbBXRC69hg",
        "outputId": "16bfd297-2b08-4000-9e5b-c979ec163707"
      },
      "outputs": [],
      "source": [
        "test_scaling_stats"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### 2.6. Feature Selection"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6z8-XnVE8-zA"
      },
      "outputs": [],
      "source": [
        "knn = KNeighborsClassifier(p=1)\n",
        "\n",
        "feature_names = np.array(data_std.drop)\n",
        "\n",
        "X_train, X_test, Y_train, Y_test = temporal_data_split(data_std, 'drought')\n",
        "X = data_std.drop('drought', axis=1)\n",
        "y = data_std['drought']\n",
        "\n",
        "sfs_forward_knn = SequentialFeatureSelector(\n",
        "    knn, n_features_to_select=50, direction=\"forward\"\n",
        ").fit(X, y)\n",
        "\n",
        "sfs_backward_knn = SequentialFeatureSelector(\n",
        "    knn, n_features_to_select=50, direction=\"backward\"\n",
        ").fit(X, y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "feature_names = np.array(data_std.drop('drought', axis=1).columns)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YF4N2XNxRdLO"
      },
      "outputs": [],
      "source": [
        "# n_features = 50\n",
        "features_selected_knn_forward = feature_names[sfs_forward_knn.get_support()]\n",
        "features_selected_knn_backward = feature_names[sfs_backward_knn.get_support()]\n",
        "\n",
        "data_features_selected_knn_forward = data_std[features_selected_knn_forward]\n",
        "data_features_selected_knn_backward = data_std[features_selected_knn_backward]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "data_features_selected_knn_forward.to_csv(\"intermediate_data/data_step_fs_knn_forward.csv\", encoding='utf-8', index=False, columns=data_features_selected_knn_forward.columns)\n",
        "data_features_selected_knn_backward.to_csv(\"intermediate_data/data_step_fs_knn_backward.csv\", encoding='utf-8', index=False, columns=data_features_selected_knn_backward.columns)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1wCszhGSYhHL"
      },
      "outputs": [],
      "source": [
        "features_selection_scaling_stats = pd.DataFrame(columns=['estimator', 'direction',\n",
        "                                                'knn_accuracy', 'knn_tn', 'knn_fp', 'knn_fn', 'knn_tp', \n",
        "                                                'nb_accuracy', 'nb_tn', 'nb_fp', 'nb_fn', 'nb_tp'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "tmp_data_features_selected_knn_forward = data_features_selected_knn_forward\n",
        "tmp_data_features_selected_knn_forward['drought'] = data_std['drought']\n",
        "tmp_data_features_selected_knn_forward"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RPBLqe-0XdQE"
      },
      "outputs": [],
      "source": [
        "\n",
        "X_train, X_test, Y_train, Y_test = temporal_data_split(tmp_data_features_selected_knn_forward, 'drought')\n",
        "knn_acc, knn_tn, knn_fp, knn_fn, knn_tp = knn(X_train, X_test, Y_train, Y_test)\n",
        "nb_acc, nb_tn, nb_fp, nb_fn, nb_tp  = nb(X_train, X_test, Y_train, Y_test)\n",
        "\n",
        "\n",
        "features_selection_scaling_stats.loc[0] = ['knn', 'forward', \n",
        "                                          knn_acc, knn_tn, knn_fp, knn_fn, knn_tp,\n",
        "                                          nb_acc, nb_tn, nb_fp, nb_fn, nb_tp]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "tmp_data_features_selected_knn_backward = data_features_selected_knn_backward\n",
        "tmp_data_features_selected_knn_backward['drought'] = data_std['drought']\n",
        "tmp_data_features_selected_knn_backward"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6CuyupiiYJYd"
      },
      "outputs": [],
      "source": [
        "X_train, X_test, Y_train, Y_test = temporal_data_split(tmp_data_features_selected_knn_backward, 'drought')\n",
        "knn_acc, knn_tn, knn_fp, knn_fn, knn_tp = knn(X_train, X_test, Y_train, Y_test)\n",
        "nb_acc, nb_tn, nb_fp, nb_fn, nb_tp  = nb(X_train, X_test, Y_train, Y_test)\n",
        "\n",
        "features_selection_scaling_stats.loc[1] = ['knn', 'backward',\n",
        "                                          knn_acc, knn_tn, knn_fp, knn_fn, knn_tp,\n",
        "                                          nb_acc, nb_tn, nb_fp, nb_fn, nb_tp]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "m7PF6c7CYJtE"
      },
      "outputs": [],
      "source": [
        "features_selection_scaling_stats"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "tmp_data_features_selected_knn_backward.to_csv(\"intermediate_data/data_prepared.csv\", encoding='utf-8', index=False, columns=tmp_data_features_selected_knn_backward.columns)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.7 (main, Sep  5 2022, 13:12:31) [GCC 11.2.0]"
    },
    "vscode": {
      "interpreter": {
        "hash": "7d6993cb2f9ce9a59d5d7380609d9cb5192a9dedd2735a011418ad9e827eb538"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
